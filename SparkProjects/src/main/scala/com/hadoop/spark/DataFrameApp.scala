package com.hadoop.spark
import org.apache.spark.sql.SparkSession
/**
  * DataFrame API åŸºæœ¬æ“ä½œ
  */
object DataFrameApp {

  def main(args: Array[String]): Unit = {

    val spark = SparkSession.builder().appName("DataFrameApp").master("local[2]").getOrCreate()

    //æŠŠjsonæ–‡ä»¶åŠ è½½æˆDataFrame
    val peopledataframe = spark.read.format("json").load("file:///Users/chandler/Documents/Projects/SparkProjects/people.json")

    //è¾“å‡ºdataframeå¯¹åº”çš„Schemaä¿¡æ¯
    peopledataframe.printSchema()

    //showçš„æ–¹æ³•æ¥å¾—åˆ°æˆ‘ä»¬çš„å†…å®¹(æ³¨æ„showæ–¹æ³•é»˜è®¤åªæ˜¾ç¤º20æ¡æ•°æ®ï¼Œè¦æƒ³æ˜¾ç¤ºå¤šå°‘å¯ä»¥è‡ªå·±ğŸˆ¯ï¸æŒ‡å®šï¼Œåœ¨æ‹¬å·å†…è¾“å…¥å¤šå°‘æ¡å°±å¯ä»¥äº†)
    peopledataframe.show()

    //åªè¾“å‡ºnameè¿™ä¸€åˆ—:select name from table
    peopledataframe.select("name").show()

    //æŸ¥è¯¢æŸå‡ åˆ—æ•°æ®ï¼Œå¹¶ä¸”å¯¹åˆ—è¿›è¡Œè®¡ç®—ï¼šselect name, age+10 as age2 from table
    peopledataframe.select(peopledataframe.col("name"), (peopledataframe.col("age")+10).as("age2")).show()

    //æŸ¥è¯¢å¹´é¾„å¤§äº20å²ï¼Œä¹Ÿå°±æ˜¯è¿‡æ»¤æ•°æ®ï¼šselect * from table where age > 20
    peopledataframe.filter(peopledataframe.col("age") > 20).show()

    //æ ¹æ®æŸä¸€åˆ—è¿›è¡Œåˆ†ç»„ï¼Œç„¶åå†è¿›è¡Œèšåˆæ“ä½œï¼šselect age,count(1) from table group by age
    peopledataframe.groupBy("age").count().show()

    spark.stop()
  }
}
